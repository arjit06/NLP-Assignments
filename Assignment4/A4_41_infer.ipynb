{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel, BertConfig, BertForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_path= './val_file.json' #\"/kaggle/input/erc-and-efr/val_file.json\"\n",
    "\n",
    "with open(val_path) as f:\n",
    "    val_list = json.load(f)\n",
    "\n",
    "\n",
    "\n",
    "val_list,test_list=train_test_split(val_list, test_size=0.1, random_state=42)\n",
    "\n",
    "\n",
    "# create test.json\n",
    "test_data=[]\n",
    "for item in test_list:\n",
    "    episode = item['episode']\n",
    "    speakers = item['speakers']\n",
    "    emotions = item['emotions']\n",
    "    utterances = item['utterances']\n",
    "    triggers = item['triggers']\n",
    "    item_dict = {\n",
    "        'episode': episode,\n",
    "        'speakers': speakers,\n",
    "        'emotions': emotions,\n",
    "        'utterances': utterances,\n",
    "        'triggers': triggers\n",
    "    }\n",
    "    test_data.append(item_dict)\n",
    "\n",
    "json_string = json.dumps(test_data)\n",
    "with open('./test_file.json', 'w') as f:\n",
    "    f.write(json_string)\n",
    "\n",
    "label_map = {'anger':0, 'surprise':1, 'sadness':2, 'neutral':3, 'fear':4, 'joy':5, 'disgust':6}  # Map emotions to labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_for_ERC_Model1(dialogues,emotions,tokenizer,max_len):\n",
    "     global label_map\n",
    "     input_ids = []\n",
    "     attention_masks=[]\n",
    "     for i in range(len(dialogues)):\n",
    "          for j in range(len(dialogues[i])):\n",
    "              window_text = ' [SEP] '.join(dialogues[i][max(0,j-4):j+1])  # Concatenate the current utterance with previous 5 utterances if possible\n",
    "              encoded_input = tokenizer(window_text, return_tensors='pt',padding='max_length', truncation=True, max_length=max_len)\n",
    "              input_ids.append(encoded_input['input_ids'].flatten())\n",
    "              attention_masks.append(encoded_input['attention_mask'].flatten())\n",
    "\n",
    "     labels = torch.tensor([label_map[emotion] for emotion in emotions])\n",
    "     return input_ids,attention_masks,labels\n",
    "\n",
    "\n",
    "def preprocess_for_ERC_Model2(dialogues,emotions):\n",
    "    \n",
    "    global label_map \n",
    "    # FastText model\n",
    "    fasttext_model = fasttext.load_model('./Embeddings/cc.en.300.bin') #('/kaggle/input/embeddings/cc.en.300.bin')\n",
    "    sentence_embeddings = []\n",
    "    for i in range(len(dialogues)):\n",
    "        for j in range(len(dialogues[i])):\n",
    "            sentence=dialogues[i][j] \n",
    "            word_embeddings = [fasttext_model.get_word_vector(word) for word in sentence.split()]\n",
    "            sentence_embedding = np.mean(word_embeddings, axis=0)\n",
    "            sentence_embeddings.append(torch.tensor(sentence_embedding))\n",
    "    labels = torch.tensor([label_map[emotion] for emotion in emotions])\n",
    "    sentence_embeddings=torch.stack(sentence_embeddings)\n",
    "    return sentence_embeddings,None,labels\n",
    "  \n",
    "\n",
    "def preprocess_for_EFR_Model3(dialogues,speakers,triggers,tokenizer,max_len):\n",
    "     global label_map\n",
    "     input_ids = []\n",
    "     attention_masks=[]\n",
    "     label_triggers=[]\n",
    "     lens=[]\n",
    "\n",
    "     for i in range(len(dialogues)):\n",
    "          last_text_by_a_speaker=-1\n",
    "          previous_flipped_emotion_text_by_same_speaker=-1\n",
    "          speaker=speakers[i][-1]\n",
    "          for j in range(len(dialogues[i])-1,-1,-1):\n",
    "              if speakers[i][j]==speaker:\n",
    "                  previous_flipped_emotion_text_by_same_speaker=j\n",
    "                  break\n",
    "\n",
    "          curr_input_ids=[]\n",
    "          curr_attention_masks=[]\n",
    "\n",
    "          for j in range(len(dialogues[i])):\n",
    "              window_text = dialogues[i][j]  # Concatenate the current utterance with previous 5 utterances if possible\n",
    "              encoded_input = tokenizer(window_text, return_tensors='pt',padding='max_length', truncation=True, max_length=max_len)\n",
    "              lens.append(len(encoded_input['input_ids'].flatten()))\n",
    "              curr_input_ids.append(encoded_input['input_ids'].flatten())\n",
    "              curr_attention_masks.append(encoded_input['attention_mask'].flatten())\n",
    "\n",
    "\n",
    "          for j in range(len(dialogues[i])):\n",
    "              curr_input_ids[j]=torch.cat((curr_input_ids[j],curr_input_ids[last_text_by_a_speaker],curr_input_ids[previous_flipped_emotion_text_by_same_speaker]),dim=0)\n",
    "              curr_attention_masks[j]=torch.cat((curr_attention_masks[j],curr_attention_masks[last_text_by_a_speaker],curr_attention_masks[previous_flipped_emotion_text_by_same_speaker]),dim=0)\n",
    "\n",
    "          input_ids.extend(curr_input_ids)\n",
    "          attention_masks.extend(curr_attention_masks)\n",
    "          \n",
    "          try:\n",
    "              k=sum(triggers[i])\n",
    "          except:\n",
    "                 for a in range(len(triggers[i])):\n",
    "                     if triggers[i][a]==None: triggers[i][a]=0.0\n",
    "\n",
    "          label_triggers.extend(triggers[i]) # skip those instances where triggers has None values\n",
    "     return input_ids,attention_masks,label_triggers\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_for_EFR_Model4(dialogues,emotions,speakers,triggers):\n",
    "    global label_map \n",
    "    # FastText model\n",
    "    fasttext_model = fasttext.load_model('./Embeddings/cc.en.300.bin') #('/kaggle/input/embeddings/cc.en.300.bin')\n",
    "    sentence_embeddings = []\n",
    "    label_triggers=[]\n",
    "    for i in range(len(dialogues)):\n",
    "        last_text_by_a_speaker=-1\n",
    "        previous_flipped_emotion_text_by_same_speaker=-1\n",
    "        speaker=speakers[i][-1]\n",
    "        for j in range(len(dialogues[i])-1,-1,-1):\n",
    "            if speakers[i][j]==speaker:\n",
    "                previous_flipped_emotion_text_by_same_speaker=j\n",
    "                break\n",
    "\n",
    "        curr_sentence_embeddings=[]\n",
    "          \n",
    "        for j in range(len(dialogues[i])):\n",
    "            sentence=dialogues[i][j] \n",
    "            word_embeddings = [fasttext_model.get_word_vector(word) for word in sentence.split()]\n",
    "            sentence_embedding = np.mean(word_embeddings, axis=0)\n",
    "            curr_sentence_embeddings.append(torch.tensor(sentence_embedding))\n",
    "            \n",
    "            \n",
    "        for j in range(len(dialogues[i])):\n",
    "            curr_sentence_embeddings[j]=torch.cat((curr_sentence_embeddings[j],curr_sentence_embeddings[last_text_by_a_speaker],curr_sentence_embeddings[previous_flipped_emotion_text_by_same_speaker]),dim=0)\n",
    "            \n",
    "\n",
    "        sentence_embeddings.extend(curr_sentence_embeddings)\n",
    "        \n",
    "        try:\n",
    "            k=sum(triggers[i])\n",
    "        except:\n",
    "                for a in range(len(triggers[i])):\n",
    "                    if triggers[i][a]==None: triggers[i][a]=0.0\n",
    "\n",
    "        label_triggers.extend(triggers[i]) # skip those instances where triggers has None values\n",
    "            \n",
    "\n",
    "    sentence_embeddings=torch.stack(sentence_embeddings)\n",
    "    return sentence_embeddings,None,label_triggers\n",
    "  \n",
    "\n",
    "\n",
    "def preprocess_model(dialogues,emotions,speakers_per_dialogue,triggers,tokenizer,max_len,Type='M1'):\n",
    "    if Type=='M1' :\n",
    "         return preprocess_for_ERC_Model1(dialogues,emotions,tokenizer,max_len)\n",
    "\n",
    "    elif Type=='M2':\n",
    "          return preprocess_for_ERC_Model2(dialogues,emotions)\n",
    "\n",
    "    elif Type=='M3':\n",
    "         return preprocess_for_EFR_Model3(dialogues,speakers_per_dialogue,triggers,tokenizer,max_len)\n",
    "\n",
    "    elif Type=='M4':\n",
    "          return preprocess_for_EFR_Model4(dialogues,emotions,speakers_per_dialogue,triggers)\n",
    "    \n",
    "\n",
    "def evaluator(gpu=\"F\",checkpoint_dir=\"\",Type='M1',batch_size=32,test_path='./test_file.json',model=None,max_len=192,criterion=nn.CrossEntropyLoss()):\n",
    "    device = torch.device(\"cuda:3\") if gpu == \"T\" else torch.device(\"cpu\")\n",
    "    \n",
    "    if gpu=='F': checkpoint=torch.load(checkpoint_dir+f\"last_checkpoint.pt\",map_location=torch.device('cpu'))\n",
    "    else: checkpoint=torch.load(checkpoint_dir+f\"last_checkpoint.pt\")\n",
    "     \n",
    "    model=model #initialize_model(Type=Type)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "\n",
    "\n",
    "    with open(test_path) as f:\n",
    "        test_list = json.load(f)\n",
    "\n",
    "\n",
    "    test_data=[]\n",
    "    for item in test_list:\n",
    "        episode = item['episode']\n",
    "        speakers = item['speakers']\n",
    "        emotions = item['emotions']\n",
    "        utterances = item['utterances']\n",
    "        triggers = item['triggers']\n",
    "        test_data.append({'utterances':utterances,'emotions':emotions, 'triggers':triggers, 'speakers':speakers})\n",
    "\n",
    "\n",
    "\n",
    "    data=test_data\n",
    "    test_dataset=EmotionDataset(test_data,max_len=max_len,Type=Type)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "    predictions=[]\n",
    "    true_labels=[]\n",
    "    total_test_loss=0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_dataloader:\n",
    "            if Type=='M1':\n",
    "                input_ids=batch[0].to(device)\n",
    "                attention_masks=batch[1].to(device)\n",
    "                labels=batch[2].to(device)\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_masks,labels=labels)\n",
    "                loss = outputs.loss\n",
    "                total_test_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.logits, 1)\n",
    "                predictions.extend(predicted.cpu().numpy())\n",
    "                true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            if Type=='M2':\n",
    "                sentence_embeddings=batch[0].to(device)\n",
    "                labels=batch[1].to(device)\n",
    "                outputs = model(sentence_embeddings)\n",
    "                loss = criterion(outputs, labels)\n",
    "                total_test_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                predictions.extend(predicted.cpu().numpy())\n",
    "                true_labels.extend(labels.cpu().numpy())\n",
    "                \n",
    "            if Type=='M3':\n",
    "                input_ids=batch[0].to(device)\n",
    "                attention_masks=batch[1].to(device)\n",
    "                labels=batch[2].to(device)\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_masks,labels=labels)\n",
    "                loss = outputs.loss\n",
    "                total_test_loss += loss.item()\n",
    "                preds = outputs.logits.squeeze().detach().cpu().numpy()\n",
    "                binary_preds = np.where(preds > 0.5, 1, 0)\n",
    "                predictions.extend(binary_preds)\n",
    "                true_labels.extend(labels.cpu().numpy())\n",
    "                \n",
    "            if Type=='M4':\n",
    "                sentence_embeddings=batch[0].to(device)\n",
    "                labels=batch[1].to(device)\n",
    "                labels = torch.round(labels).long()\n",
    "                outputs = model(sentence_embeddings)\n",
    "                loss = criterion(outputs, labels)\n",
    "                total_test_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                predictions.extend(predicted.cpu().numpy())\n",
    "                true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_test_loss = total_test_loss / len(true_labels)\n",
    "    test_accuracy = accuracy_score(true_labels, predictions)\n",
    "    test_f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "\n",
    "    print(f'Average Test Loss: {avg_test_loss:.4f}, Test accuracy: {test_accuracy:.4f}, Test F1 score: {test_f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "bert_for_classification=BertForSequenceClassification.from_pretrained(model_name, num_labels=7)\n",
    "bert_for_regression=BertForSequenceClassification.from_pretrained(model_name, num_labels=1)\n",
    "bert_model=BertModel.from_pretrained(model_name)\n",
    "\n",
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, data,max_len=192,Type='M1'):\n",
    "        self.data = data\n",
    "        self.dialogues=[item['utterances'] for item in data] # list of dialogues  (a dialogue is a list of utterances)\n",
    "        self.emotions = [emotion for item in data for emotion in item['emotions']]  # list of emotions (concatenated for all dialogues)\n",
    "        self.emotion_per_dialogue= [item['emotions'] for item in data]\n",
    "        self.speakers_per_dialogue= [item['speakers'] for item in data]\n",
    "        self.triggers=[item['triggers'] for item in data] # list of triggers of each dialogue\n",
    "        \n",
    "        self.max_len=max_len\n",
    "        self.max_emotion_pad_len=26\n",
    "        self.Type=Type\n",
    "        self.tokenizer=tokenizer\n",
    "        self.bert_model=bert_model\n",
    "        \n",
    "        self.input_ids,self.attention_masks,self.labels=preprocess_model(self.dialogues,self.emotions,self.speakers_per_dialogue,self.triggers,self.tokenizer,self.max_len,Type)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.Type=='M1' or self.Type=='M3':\n",
    "            if (self.Type=='M3'): self.labels= torch.tensor(self.labels, dtype=torch.float) #self.labels.clone().detach().to(torch.float)\n",
    "            return self.input_ids[idx], self.attention_masks[idx],self.labels[idx]\n",
    "\n",
    "        if self.Type=='M2' or self.Type=='M4':\n",
    "            if (self.Type=='M4'): self.labels= torch.tensor(self.labels, dtype=torch.float)\n",
    "            return self.input_ids[idx],self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, output_dim):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.gru = nn.GRU(input_size=embedding_dim, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "   \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        gru_output, _ = self.gru(x)\n",
    "        output = self.fc(gru_output[:, -1, :])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss: 0.0017, Test accuracy: 0.9908, Test F1 score: 0.9908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss: 0.0442, Test accuracy: 0.4653, Test F1 score: 0.4072\n",
      "Average Test Loss: 0.0040, Test accuracy: 0.8532, Test F1 score: 0.7856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss: 0.0149, Test accuracy: 0.8532, Test F1 score: 0.7856\n"
     ]
    }
   ],
   "source": [
    "# Test has 60 samples\n",
    "# 6 min on cpu \n",
    "evaluator(\n",
    "    gpu='F',\n",
    "    checkpoint_dir=\"./checkpoints/Task1_M1/\",\n",
    "    Type='M1',\n",
    "    batch_size=32,\n",
    "    test_path='./test_file.json',\n",
    "    model=bert_for_classification, \n",
    "    max_len=192\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "evaluator(\n",
    "    gpu='F',\n",
    "    checkpoint_dir=\"./checkpoints/Task1_M2/\",\n",
    "    Type='M2',\n",
    "    batch_size=32, \n",
    "    test_path='./test_file.json',\n",
    "    model=GRUModel(embedding_dim=300, hidden_dim=128, output_dim=7)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss: 0.0040, Test accuracy: 0.8532, Test F1 score: 0.7856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss: 0.0149, Test accuracy: 0.8532, Test F1 score: 0.7856\n"
     ]
    }
   ],
   "source": [
    "evaluator(\n",
    "    gpu='F',\n",
    "    checkpoint_dir=\"./checkpoints/Task2_M3/\",\n",
    "    Type='M3',\n",
    "    batch_size=32, \n",
    "    test_path='./test_file.json',\n",
    "    model=bert_for_regression, \n",
    "    max_len=112\n",
    ")\n",
    "\n",
    "\n",
    "evaluator(\n",
    "    gpu='F',\n",
    "    checkpoint_dir=\"./checkpoints/Task2_M4/\",\n",
    "    Type='M4',\n",
    "    batch_size=32, \n",
    "    test_path='./test_file.json',\n",
    "    model=GRUModel(embedding_dim=300*3, hidden_dim=128, output_dim=2)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
